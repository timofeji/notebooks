{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to make inferences about the real world is hard because looking at a picture doesn't tell us how the movie ends. Similarly, knowing an image is predominantly made of red color, doesn't tell us what the image depics. This is the curse of dimensionality.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "manifold hypothesis:\n",
    "\n",
    "\n",
    "\n",
    "flatland(paper mario):\n",
    "\n",
    "\n",
    "\n",
    "models that take points in high-dimensional spaces and translate them to lower-dimensions\n",
    "\n",
    "$\n",
    "\\operatorname{Cov}(x, y) = \\frac{\\sum_{i=1}^{n} (x_i - \\overline{x})(y_i - \\overline{y})}{n - 1}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tensor_transform = transforms.ToTensor()\n",
    "dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=tensor_transform)\n",
    "loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoEncoder:\n",
    "an autoencoder is a neural network that learns a dimensionality reduction transformation $ T(x) $ over a vector space $ X $ to a lower dimensional space $ Z $\n",
    "\n",
    "\n",
    "$ T(x) $ is composed of two parts: \n",
    "- encoder $ e(x) : X \\rightarrow Z $ \n",
    "- decoder $ d(z) : Z \\rightarrow \\hat{X} $ \n",
    "\n",
    "where $x \\in X$ and $z \\in Z$ respectively\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "\\text{Definition: Vector Space } V \\text{ over a Field } \\mathbb{F} \\\\\n",
    "\\text{A vector space } V \\text{ is a set with two operations:} \\\\\n",
    "\\begin{itemize}\n",
    "    \\item \\text{Vector Addition: } + : V \\times V \\to V \\\\\n",
    "    \\item \\text{Scalar Multiplication: } \\cdot : \\mathbb{F} \\times V \\to V\n",
    "\\end{itemize}\n",
    "\n",
    "\\text{Satisfying the following axioms } \\forall \\vec{u}, \\vec{v}, \\vec{w} \\in V \\text{ and } a, b \\in \\mathbb{F}:\n",
    "\n",
    "\\begin{array}{l}\n",
    "1. \\text{Commutativity of Addition:} \\quad \\vec{u} + \\vec{v} = \\vec{v} + \\vec{u} \\\\\n",
    "2. \\text{Associativity of Addition:} \\quad (\\vec{u} + \\vec{v}) + \\vec{w} = \\vec{u} + (\\vec{v} + \\vec{w}) \\\\\n",
    "3. \\text{Zero Vector Existence:} \\quad \\exists \\vec{0} \\in V : \\vec{u} + \\vec{0} = \\vec{u} \\\\\n",
    "4. \\text{Additive Inverse:} \\quad \\exists (-\\vec{u}) : \\vec{u} + (-\\vec{u}) = \\vec{0} \\\\\n",
    "5. \\text{Distributivity of Scalar Multiplication:} \\quad a \\cdot (\\vec{u} + \\vec{v}) = a \\cdot \\vec{u} + a \\cdot \\vec{v} \\\\\n",
    "6. \\text{Distributivity of Field Addition:} \\quad (a + b) \\cdot \\vec{u} = a \\cdot \\vec{u} + b \\cdot \\vec{u} \\\\\n",
    "7. \\text{Associativity of Scalar Multiplication:} \\quad a \\cdot (b \\cdot \\vec{u}) = (ab) \\cdot \\vec{u} \\\\\n",
    "8. \\text{Identity of Scalar Multiplication:} \\quad 1 \\cdot \\vec{u} = \\vec{u}\n",
    "\\end{array}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 36),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(36, 18),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(18, 9)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(9, 18),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(18, 36),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(36, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 28 * 28),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "model = AE()\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.041101\n",
      "Epoch 2/20, Loss: 0.035199\n",
      "Epoch 3/20, Loss: 0.035375\n",
      "Epoch 4/20, Loss: 0.028708\n",
      "Epoch 5/20, Loss: 0.024045\n",
      "Epoch 6/20, Loss: 0.029022\n",
      "Epoch 7/20, Loss: 0.023514\n",
      "Epoch 8/20, Loss: 0.025121\n",
      "Epoch 9/20, Loss: 0.023180\n",
      "Epoch 10/20, Loss: 0.022368\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "outputs = []\n",
    "losses = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for images, _ in loader:\n",
    "        images = images.view(-1, 28 * 28).to(device)\n",
    "        \n",
    "        reconstructed = model(images)\n",
    "        loss = loss_function(reconstructed, images)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    outputs.append((epoch, images, reconstructed))\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.6f}\")\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(losses, label='Loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mloader\u001b[49m):\n\u001b[0;32m      2\u001b[0m     z \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencoder(x\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m      3\u001b[0m     z \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loader' is not defined"
     ]
    }
   ],
   "source": [
    "for i, (x, y) in enumerate(loader):\n",
    "    z = model.encoder(x.to(device))\n",
    "    z = z.to('cpu').detach().numpy()\n",
    "    plt.scatter(z[:, 0], z[:, 1], c=y, cmap='tab10')\n",
    "    if i > 32:\n",
    "        plt.colorbar()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m             img[(n\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mi)\u001b[38;5;241m*\u001b[39mw:(n\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mw, j\u001b[38;5;241m*\u001b[39mw:(j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mw] \u001b[38;5;241m=\u001b[39m x_hat\n\u001b[0;32m     10\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(img, extent\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m*\u001b[39mr0, \u001b[38;5;241m*\u001b[39mr1])\n\u001b[1;32m---> 12\u001b[0m \u001b[43mplot_reconstructed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m, in \u001b[0;36mplot_reconstructed\u001b[1;34m(autoencoder, r0, r1, n)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_reconstructed\u001b[39m(autoencoder, r0\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m), r1\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m), n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m):\n\u001b[0;32m      2\u001b[0m     w \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m28\u001b[39m\n\u001b[1;32m----> 3\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mzeros((n\u001b[38;5;241m*\u001b[39mw, n\u001b[38;5;241m*\u001b[39mw))\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m*\u001b[39mr1, n)):\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m j, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m*\u001b[39mr0, n)):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_reconstructed(autoencoder, r0=(-5, 10), r1=(-10, 5), n=12):\n",
    "    w = 28\n",
    "    img = np.zeros((n*w, n*w))\n",
    "    for i, y in enumerate(np.linspace(*r1, n)):\n",
    "        for j, x in enumerate(np.linspace(*r0, n)):\n",
    "            z = torch.Tensor([[x, y]]).to(device)\n",
    "            x_hat = autoencoder.decoder(z)\n",
    "            x_hat = x_hat.reshape(28, 28).to('cpu').detach().numpy()\n",
    "            img[(n-1-i)*w:(n-1-i+1)*w, j*w:(j+1)*w] = x_hat\n",
    "    plt.imshow(img, extent=[*r0, *r1])\n",
    "\n",
    "plot_reconstructed(model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUT if I tried to pass any other different image (outlier or anomaly), we will get a high reconstruction loss value because the network failed to reconstruct the image/input that is considered an anomaly.\n",
    "\n",
    "\n",
    "You may have noticed that there are “gaps” in the latent space, where data is never mapped to. This becomes a problem when we try to use autoencoders as generative models.\n",
    "gradients cannot flow through sampling (which is a non-differentiable operation). \n",
    "\n",
    "\n",
    "# Deep Latent Variable Models\n",
    "we are interested in learning the latent distribution conditioned only on our data: p(z|x)\n",
    "\n",
    "$p(z|x) = \\frac{p(x|z)p(z)}{p(x)}$ - bayes rule:\n",
    "\n",
    "the problem is that \n",
    "\n",
    "\n",
    "$ p_θ(x) = \\int p_θ(x, z)d\\theta $\n",
    "\n",
    "this is called the model evidence\n",
    "How likely are the observed data, considering all possible parameter configurations?\n",
    "\n",
    "\n",
    "$p(x)$ is intractable\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$ p_θ(x)  = z $\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "decoder = p(x|z)p(z)\n",
    "\n",
    "\n",
    "\n",
    "inference model:\n",
    "$ q_θ(z|x)  \\approx  p_\\theta(z|x) $\n",
    "\n",
    "\n",
    "## Evidence Lower Bound:\n",
    "\n",
    "\n",
    "$ log p(x) = \\mathbb{E}[\\log p_\\theta(x)]$\n",
    "\n",
    "$ log p(x) = \\mathbb{E}[log[\\frac{p_\\theta(x, z)}{p(z|x)}]]$\n",
    "\n",
    "\n",
    "$ log p(x) = \\mathbb{E}[\\frac{logp_\\theta(x) p_\\theta(x, z)   q_\\phi(x, z) }{p(z|x) q_\\phi(x, z) }]$\n",
    "\n",
    "$ L_{\\theta, \\phi}(x) =\\mathbb{E}[log [p_\\theta(x,z)] - log q_\\phi(z|x)] $\n",
    "\n",
    "$ L_{\\theta, \\phi}(x) \\le  \\log p_θ(x)$\n",
    "\n",
    "$D_\\mathbb{KL}\\left( \\mathcal{N}(\\mu, \\sigma) \\parallel \\mathcal{N}(0, 1) \\right) = \\sum_{x \\in X} \\left( \\sigma^2 + \\mu^2 - \\log \\sigma - \\frac{1}{2} \\right)\\ $\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Evidence Lower Bound (ELBO) Derivation\n",
    "\n",
    "The equations represent a key derivation in variational inference, specifically the Evidence Lower BOund (ELBO) for a probabilistic model:\n",
    "\n",
    "1. Starting Point:\n",
    "   $\\log p(x) = \\mathbb{E}[\\log p_\\theta(x)]$\n",
    "\n",
    "2. Introducing Latent Variable $z$:\n",
    "   $\\log p(x) = \\mathbb{E}[\\log\\left(\\frac{p_\\theta(x, z)}{p(z|x)}\\right)]$\n",
    "\n",
    "3. Rearranging Terms:\n",
    "   $\\log p(x) = \\mathbb{E}\\left[\\frac{\\log p_\\theta(x) p_\\theta(x, z) q_\\phi(x, z)}{p(z|x) q_\\phi(x, z)}\\right]$\n",
    "\n",
    "4. Evidence Lower Bound (ELBO):\n",
    "   $L_{\\theta, \\phi}(x) = \\mathbb{E}[\\log p_\\theta(x,z) - \\log q_\\phi(z|x)]$\n",
    "\n",
    "5. ELBO Inequality:\n",
    "   $L_{\\theta, \\phi}(x) \\leq \\log p_\\theta(x)$\n",
    "\n",
    "6. Kullback-Leibler Divergence for Normal Distributions:\n",
    "   $D_\\mathbb{KL}\\left( \\mathcal{N}(\\mu, \\sigma) \\parallel \\mathcal{N}(0, 1) \\right) = \\sum_{x \\in X} \\left( \\sigma^2 + \\mu^2 - \\log \\sigma - \\frac{1}{2} \\right)$\n",
    "\n",
    "### Key Notation\n",
    "- $p_\\theta(x)$: Probabilistic model with parameters $\\theta$\n",
    "- $q_\\phi(z|x)$: Variational approximation with parameters $\\phi$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$ pθ(z|x) = \\frac{pθ(x, z)}{pθ(x)}$\n",
    "\n",
    "$ p_θ(x, z) = p_θ(z)p_θ(x|z) $\n",
    "\n",
    "$p(z)$ is the prior distribution over Z\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational AutoEncoder:\n",
    "Instead of mapping an input to a fixed-point representation, VAEs learn to map inputs to a probability distribution in the latent space. Specifically, the encoder network produces two key parameters:\n",
    "\n",
    "- A mean vector (μ)\n",
    "- A variance vector (σ²)\n",
    "\n",
    "These parameters define a multivariate Gaussian distribution from which latent representations are sampled during training and inference.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "z = μ + σ ⊙ ε\n",
    "Where:\n",
    "\n",
    "z is the sampled latent representation\n",
    "μ is the mean vector\n",
    "σ is the standard deviation vector\n",
    "ε is a sample from a standard normal distribution\n",
    "⊙ represents element-wise multiplication\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 2.1.1 Fundamental Objective\n",
    "The core challenge in generative modeling is to learn a probability distribution $p_\\theta(x)$ that accurately represents the underlying data. Mathematically, we seek to maximize the log-likelihood:\n",
    "\n",
    "$\\log p(x) = \\mathbb{E}[\\log p_\\theta(x)]$\n",
    "\n",
    "#### 2.1.2 Introducing Latent Variables\n",
    "To capture complex data structures, we introduce a latent variable $z$, transforming our objective:\n",
    "\n",
    "$\\log p(x) = \\mathbb{E}\\left[\\log\\left(\\frac{p_\\theta(x, z)}{p(z|x)}\\right)\\right]$\n",
    "\n",
    "### 2.2 Evidence Lower Bound (ELBO)\n",
    "\n",
    "#### 2.2.1 Derivation\n",
    "The key insight of VAEs is the Evidence Lower Bound (ELBO), which provides a tractable optimization objective:\n",
    "\n",
    "$L_{\\theta, \\phi}(x) = \\mathbb{E}[\\log p_\\theta(x,z) - \\log q_\\phi(z|x)]$\n",
    "\n",
    "#### 2.2.2 Fundamental Inequality\n",
    "A critical property of the ELBO is its relationship to the marginal log-likelihood:\n",
    "\n",
    "$L_{\\theta, \\phi}(x) \\leq \\log p_\\theta(x)$\n",
    "\n",
    "### 2.3 Probabilistic Interpretation\n",
    "\n",
    "#### 2.3.1 Kullback-Leibler Divergence\n",
    "The ELBO incorporates the Kullback-Leibler (KL) divergence, which measures the difference between two probability distributions. For Gaussian distributions, this is particularly elegant:\n",
    "\n",
    "$D_\\mathbb{KL}\\left( \\mathcal{N}(\\mu, \\sigma) \\parallel \\mathcal{N}(0, 1) \\right) = \\sum_{x \\in X} \\left( \\sigma^2 + \\mu^2 - \\log \\sigma - \\frac{1}{2} \\right)$\n",
    "\n",
    "## Chapter 3: Practical Implementation\n",
    "\n",
    "### 3.1 Key Components\n",
    "1. **Encoder Network**: Learns $q_\\phi(z|x)$ - the approximate posterior distribution\n",
    "2. **Decoder Network**: Learns $p_\\theta(x|z)$ - the generative distribution\n",
    "3. **Reparameterization Trick**: Enables gradient-based learning of stochastic encoders\n",
    "\n",
    "## Chapter 4: Intuitive Understanding\n",
    "\n",
    "### 4.1 Conceptual Breakdown\n",
    "VAEs can be understood as a sophisticated compression technique that:\n",
    "- Learns a compressed representation of data\n",
    "- Enables generation of new, similar data points\n",
    "- Provides a probabilistic interpretation of data manifolds\n",
    "\n",
    "## Conclusion\n",
    "Variational Autoencoders represent a powerful synthesis of probabilistic modeling and deep learning, offering a principled approach to understanding and generating complex data distributions.\n",
    "\n",
    "### Recommended Further Reading\n",
    "- Kingma, D. P., & Welling, M. (2013). Auto-Encoding Variational Bayes\n",
    "- Rezende, D. J., Mohamed, S., & Wierstra, D. (2014). Stochastic Backpropagation and Approximate Inference in Deep Generative Models\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
